# Credit Risk Modelling

[![Live App](https://img.shields.io/badge/Live_App-Click_Here-blue)](https://creditrisk-modelling.streamlit.app/)

## ğŸ“Œ Overview
Credit risk modeling is essential for financial institutions to assess a borrower's likelihood of defaulting on a loan. This project provides a data-driven approach to credit risk assessment using machine learning techniques.

## ğŸš€ Live Demo
Experience the live application here: [Credit Risk Modelling](https://creditrisk-modelling.streamlit.app/)

## ğŸ“‚ Project Structure
```
credit-risk-modelling/
â”‚-- credit-risk-modelling.ipynb  # Jupyter Notebook with analysis & model training
â”‚-- artifacts/
â”‚   â”œâ”€â”€ model_data.joblib        # Trained model artifact
â”‚-- data/
â”‚   â”œâ”€â”€ bureau_data.csv          # Bureau data
â”‚   â”œâ”€â”€ customers.csv            # Customer details
â”‚   â”œâ”€â”€ loans.csv                # Loan records
â”‚-- app/
â”‚   â”œâ”€â”€ main.py                  # Streamlit application
â”‚   â”œâ”€â”€ prediction_helper.py      # Helper functions for prediction
â”‚   â”œâ”€â”€ requirements.txt          # Dependencies list
```

## âš¡ Features
- Exploratory Data Analysis (EDA) for risk factors
- Machine Learning model training and evaluation
- API for making risk predictions
- Interactive web-based application with Streamlit

## ğŸ›  Installation & Usage
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/rajat-kumar-mondal/credit-risk-modelling.git
cd credit-risk-modelling
```
### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r app/requirements.txt
```
### 3ï¸âƒ£ Run the Application
```bash
streamlit run app/main.py
```

## ğŸ“Š Dataset
The project uses multiple datasets, each containing 50K records, to analyze customer profiles and predict credit risk:
- **customers.csv**: Basic details of loan applicants
- **bureau_data.csv**: Credit history from various sources
- **loans.csv**: Information on previous and current loans

## ğŸ“¦ Libraries & Packages
The project utilizes the following key libraries:
- **pandas** â€“ Data manipulation and analysis  
- **numpy** â€“ Numerical computations  
- **matplotlib.pyplot & seaborn** â€“ Data visualization  
- **optuna** â€“ Hyperparameter optimization  
- **scikit-learn**:
  - `train_test_split` â€“ Splitting data into training and testing sets  
  - `MinMaxScaler` â€“ Feature scaling  
  - `LogisticRegression` â€“ Classification model  
  - `classification_report`, `f1_score`, `roc_curve`, `auc` â€“ Model evaluation metrics  
  - `RandomForestClassifier` â€“ Ensemble learning model  
  - `RandomizedSearchCV` â€“ Hyperparameter tuning  
- **statsmodels**:
  - `variance_inflation_factor` â€“ Detecting multicollinearity  
- **xgboost** â€“ Gradient boosting model  
- **imblearn**:
  - `RandomUnderSampler` â€“ Handling imbalanced datasets  
  - `SMOTETomek` â€“ Hybrid oversampling and undersampling method
- **joblib**:
  - `dump` â€“ Store the models and scaler objects
- **streamlit** - App user interface (UI)

## ğŸ¤– Model Training & Evaluation
The model is trained using supervised learning techniques with a focus on classification. The training process involves:
### 1ï¸âƒ£ Data Preprocessing
- Handling missing values through imputation strategies.
- Encoding categorical variables using one-hot encoding.
- Feature scaling with **MinMaxScaler**.
- Removing multicollinearity using **Variance Inflation Factor (VIF)**.

### 2ï¸âƒ£ Class Balancing
- Addressing dataset imbalance using **SMOTETomek** and **RandomUnderSampler**.

### 3ï¸âƒ£ Model Selection
Three machine learning models were trained and compared:
- **Logistic Regression**: A baseline model for classification.
- **Random Forest Classifier**: An ensemble method improving prediction stability.
- **XGBoost Classifier**: A gradient boosting method providing high accuracy.

### 4ï¸âƒ£ Hyperparameter Tuning
- **Optuna** was used for optimizing hyperparameters efficiently.
- **RandomizedSearchCV** was applied to refine model parameters.

### 5ï¸âƒ£ Model Evaluation
The models were assessed using:
- **Accuracy**: Overall correctness of predictions.
- **Precision & Recall**: Trade-off between false positives and false negatives.
- **F1-Score**: Harmonic mean of precision and recall.
- **ROC-AUC Score**: Measures model discrimination ability.
- **Cross-validation**: Ensured model robustness across different data splits.

## ğŸ“ˆ Model Performance
The best-performing model (XGBoost) achieved:
- **Accuracy**: 93%
- **Precision**: 78%
- **Recall**: 94%
- **F1-Score**: 83%
- **ROC-AUC Score**: 98%

The model provides a balanced assessment of credit risk, minimizing false positives and negatives effectively.

---

